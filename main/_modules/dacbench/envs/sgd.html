<!DOCTYPE html>

<html lang="en" data-content_root="../../../">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>dacbench.envs.sgd &#8212; DACBench Documentation 0.3.0 documentation</title>
    
  <link href="../../../_static/css/theme.css" rel="stylesheet">
  <link href="../../../_static/css/index.ac9c05f7c49ca1e1f876c6e36360ea26.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css?v=8f2a1f02" />
    <link rel="stylesheet" type="text/css" href="../../../_static/css/custom.css?v=2eb4fb78" />
    
  <link rel="preload" as="script" href="../../../_static/js/index.9ea38e314b9e6d9dab77.js">

    <script src="../../../_static/documentation_options.js?v=f129cdf0"></script>
    <script src="../../../_static/doctools.js?v=9bcbadda"></script>
    <script src="../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="container-xl">

  <div id="navbar-start">
    
    
  <a class="navbar-brand" href="../../../index.html">
  <!-- <p class="title">DACBench Documentation</p> -->
  </a>

    
  </div>

  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-collapsible" aria-controls="navbar-collapsible" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>

  
  <div id="navbar-collapsible" class="col-lg-9 collapse navbar-collapse">
    <div id="navbar-center" class="mr-auto">
      
    </div>

    <div id="navbar-end">
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="">
        <li class="nav-item">
          <a class="nav-link" href="https://github.com/automl/DACBench" rel="noopener" target="_blank" title="GitHub">
            <span><i class="fab fa-github-square"></i></span>
            <label class="sr-only">GitHub</label>
          </a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="https://twitter.com/automl_org?lang=de" rel="noopener" target="_blank" title="Twitter">
            <span><i class="fab fa-twitter-square"></i></span>
            <label class="sr-only">Twitter</label>
          </a>
        </li>
      </ul>
      </div>
      
      <div class="navbar-end-item">
        <div class="dropdown mt-1">
    <button type="button" class="btn btn-secondary btn-md navbar-btn dropdown-toggle" id="dLabelMore"
        data-toggle="dropdown">
        v0.3.0
        <span class="caret"></span>
    </button>
    <div class="dropdown-menu list-group-flush py-0" aria-labelledby="dLabelMore">
        <a class="list-group-item list-group-item-action" href="#">v0.3.0</a>
    </div>
</div>
      </div>
      
      <div class="navbar-end-item">
        <form class="bd-search align-items-center" action="../../../search.html" method="get" style="width: 100%;">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control btn btn-md" name="q" id="search-input"
    placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off">
</form>
      </div>
      
    </div>
  </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
            
            <!-- Only show if we have sidebars configured, else just a small margin  -->
            <div class="col-12 col-md-3 bd-sidebar"><h4 class="mt-0 mb-0"><a href="../../../index.html">DACBench Documentation</a></h4>
<div class="mb-3">v0.3.0</div><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Getting Started:
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../../source/dac.html">
   Dynamic Algorithm Configuration - A Short Overview
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../source/installation.html">
   How to Install DACBench
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../source/containers.html">
   Using DACBench Containers
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  The Benchmarks:
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../../source/benchmarks.html">
   Benchmark Overview
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../source/benchmark_docs/function_approximation.html">
   The Function Approximation Toy Benchmark
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../source/benchmark_docs/luby.html">
   The Luby Toy Benchmark
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../source/benchmark_docs/toy_sgd.html">
   The ToySGD Benchmark
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../source/benchmark_docs/theory.html">
   The Theory Benchmark
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../source/benchmark_docs/cma.html">
   The CMA-ES Benchmark
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../source/benchmark_docs/sgd.html">
   The SGD Deep Learning Benchmark
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Using DACBench:
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../../source/modifications.html">
   Saving &amp; Loading Benchmark Configurations
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../source/multi_agent_dac.html">
   Multi-Agent DAC
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../source/state_and_reward.html">
   Modifying Observations &amp; Cost
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../source/wrappers.html">
   Functionality through Wrappers
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../source/logging.html">
   Logging Experiments
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../source/plotting.html">
   Plotting results
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Misc:
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../../source/contrib.html">
   Contributing to DACBench
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../source/cite.html">
   Citing DACBench
  </a>
 </li>
</ul>

  </div>
</nav>
            </div>
            
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
            
          </div>
          

          
          
            
          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <h1>Source code for dacbench.envs.sgd</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot;SGD environment.&quot;&quot;&quot;</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">__future__</span><span class="w"> </span><span class="kn">import</span> <span class="n">annotations</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">dataclasses</span><span class="w"> </span><span class="kn">import</span> <span class="n">dataclass</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">dacbench</span><span class="w"> </span><span class="kn">import</span> <span class="n">AbstractMADACEnv</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">dacbench.envs.env_utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">sgd_utils</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">dacbench.envs.env_utils.sgd_utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">random_torchvision_loader</span>


<div class="viewcode-block" id="test">
<a class="viewcode-back" href="../../../source/benchmark_docs/sgd.html#dacbench.envs.sgd.test">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">test</span><span class="p">(</span>
    <span class="n">model</span><span class="p">,</span>
    <span class="n">loss_function</span><span class="p">,</span>
    <span class="n">loader</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="p">,</span>
    <span class="n">batch_percentage</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
    <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cpu&quot;</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Evaluate given `model` on `loss_function`.</span>

<span class="sd">    Percentage defines how much percentage of the data shall be used.</span>
<span class="sd">    If nothing given the whole data is used.</span>

<span class="sd">    Returns:</span>
<span class="sd">        test_losses: Batch validation loss per data point</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">nmb_sets</span> <span class="o">=</span> <span class="n">batch_percentage</span> <span class="o">*</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">loader</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span> <span class="o">/</span> <span class="n">batch_size</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="n">test_losses</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">test_accuracies</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="k">for</span> <span class="n">data</span><span class="p">,</span> <span class="n">target</span> <span class="ow">in</span> <span class="n">loader</span><span class="p">:</span>
            <span class="n">d_data</span><span class="p">,</span> <span class="n">d_target</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">target</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">d_data</span><span class="p">)</span>
            <span class="n">_</span><span class="p">,</span> <span class="n">preds</span> <span class="o">=</span> <span class="n">output</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">test_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss_function</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">d_target</span><span class="p">))</span>
            <span class="n">test_accuracies</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">preds</span> <span class="o">==</span> <span class="n">target</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">target</span><span class="p">))</span>
            <span class="n">i</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="k">if</span> <span class="n">i</span> <span class="o">&gt;=</span> <span class="n">nmb_sets</span><span class="p">:</span>
                <span class="k">break</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">test_losses</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">test_accuracies</span><span class="p">)</span></div>



<div class="viewcode-block" id="forward_backward">
<a class="viewcode-back" href="../../../source/benchmark_docs/sgd.html#dacbench.envs.sgd.forward_backward">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">forward_backward</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">loss_function</span><span class="p">,</span> <span class="n">loader</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cpu&quot;</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Do a forward and a backward pass for given `model` for `loss_function`.</span>

<span class="sd">    Returns:</span>
<span class="sd">        loss: Mini batch training loss per data point</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
    <span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">loader</span><span class="p">))</span>
    <span class="n">data</span><span class="p">,</span> <span class="n">target</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">target</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
    <span class="n">loss</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">loss</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span></div>



<div class="viewcode-block" id="run_epoch">
<a class="viewcode-back" href="../../../source/benchmark_docs/sgd.html#dacbench.envs.sgd.run_epoch">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">run_epoch</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">loss_function</span><span class="p">,</span> <span class="n">loader</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cpu&quot;</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Run a single epoch of training for given `model` with `loss_function`.&quot;&quot;&quot;</span>
    <span class="n">last_loss</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">running_loss</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">data</span><span class="p">,</span> <span class="n">target</span> <span class="ow">in</span> <span class="n">loader</span><span class="p">:</span>
        <span class="n">data</span><span class="p">,</span> <span class="n">target</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">target</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
        <span class="n">last_loss</span> <span class="o">=</span> <span class="n">loss</span>
        <span class="n">running_loss</span> <span class="o">+=</span> <span class="n">last_loss</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">last_loss</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">(),</span> <span class="n">running_loss</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">loader</span><span class="p">)</span></div>



<div class="viewcode-block" id="SGDInstance">
<a class="viewcode-back" href="../../../source/benchmark_docs/sgd.html#dacbench.envs.sgd.SGDInstance">[docs]</a>
<span class="nd">@dataclass</span>
<span class="k">class</span><span class="w"> </span><span class="nc">SGDInstance</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;SGD Instance.&quot;&quot;&quot;</span>

    <span class="n">model</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span>
    <span class="n">optimizer_type</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Optimizer</span>
    <span class="n">optimizer_params</span><span class="p">:</span> <span class="nb">dict</span>
    <span class="n">dataset_path</span><span class="p">:</span> <span class="nb">str</span>
    <span class="n">dataset_name</span><span class="p">:</span> <span class="nb">str</span>
    <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span>
    <span class="n">fraction_of_dataset</span><span class="p">:</span> <span class="nb">float</span>
    <span class="n">train_validation_ratio</span><span class="p">:</span> <span class="nb">float</span>
    <span class="n">seed</span><span class="p">:</span> <span class="nb">int</span></div>



<div class="viewcode-block" id="SGDEnv">
<a class="viewcode-back" href="../../../source/benchmark_docs/sgd.html#dacbench.envs.sgd.SGDEnv">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">SGDEnv</span><span class="p">(</span><span class="n">AbstractMADACEnv</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;The SGD DAC Environment implements the problem of dynamically configuring</span>
<span class="sd">    the learning rate hyperparameter of a neural network optimizer</span>
<span class="sd">    (more specifically, torch.optim.AdamW) for a supervised learning task.</span>
<span class="sd">    While training, the model is evaluated after every epoch.</span>

<span class="sd">    Actions correspond to learning rate values in [0,+inf[</span>
<span class="sd">    For observation space check `observation_space` method docstring.</span>
<span class="sd">    For instance space check the `SGDInstance` class docstring</span>
<span class="sd">    Reward:</span>
<span class="sd">        negative loss of model on test_loader of the instance       if done</span>
<span class="sd">        crash_penalty of the instance                               if crashed</span>
<span class="sd">        0                                                           otherwise</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">metadata</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;render_modes&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;human&quot;</span><span class="p">]}</span>  <span class="c1"># noqa: RUF012</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Init env.&quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;seed&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">epoch_mode</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;epoch_mode&quot;</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;device&quot;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">crash_penalty</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;crash_penalty&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loss_function</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">loss_function</span><span class="p">(</span><span class="o">**</span><span class="n">config</span><span class="o">.</span><span class="n">loss_function_kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">use_generator</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;use_instance_generator&quot;</span><span class="p">)</span>

        <span class="c1"># Use default reward function, if no specific function is given</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">get_reward</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;reward_function&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_default_reward</span><span class="p">)</span>

        <span class="c1"># Use default state function, if no specific function is given</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">get_state</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;state_method&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_default_state</span><span class="p">)</span>

<div class="viewcode-block" id="SGDEnv.step">
<a class="viewcode-back" href="../../../source/benchmark_docs/sgd.html#dacbench.envs.sgd.SGDEnv.step">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">action</span><span class="p">:</span> <span class="nb">float</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Update the parameters of the neural network using the given learning rate lr,</span>
<span class="sd">        in the direction specified by AdamW, and if not done (crashed/cutoff reached),</span>
<span class="sd">        performs another forward/backward pass (update only in the next step).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">truncated</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">step_</span><span class="p">()</span>
        <span class="n">info</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">action</span><span class="p">,</span> <span class="nb">float</span><span class="p">):</span>
            <span class="n">action</span> <span class="o">=</span> <span class="p">[</span><span class="n">action</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">g</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">param_groups</span><span class="p">:</span>
            <span class="n">g</span><span class="p">[</span><span class="s2">&quot;lr&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">action</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">action</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">g</span><span class="p">[</span><span class="s2">&quot;betas&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">action</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mf">0.999</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">epoch_mode</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">average_loss</span> <span class="o">=</span> <span class="n">run_epoch</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">loss_function</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">train_loader</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">train_args</span> <span class="o">=</span> <span class="p">[</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">loss_function</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">train_loader</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
            <span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">loss</span> <span class="o">=</span> <span class="n">forward_backward</span><span class="p">(</span><span class="o">*</span><span class="n">train_args</span><span class="p">)</span>

        <span class="n">crashed</span> <span class="o">=</span> <span class="p">(</span>
            <span class="ow">not</span> <span class="n">torch</span><span class="o">.</span><span class="n">isfinite</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="p">)</span><span class="o">.</span><span class="n">any</span><span class="p">()</span>
            <span class="ow">or</span> <span class="ow">not</span> <span class="n">torch</span><span class="o">.</span><span class="n">isfinite</span><span class="p">(</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">parameters_to_vector</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span>
            <span class="p">)</span><span class="o">.</span><span class="n">any</span><span class="p">()</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

        <span class="k">if</span> <span class="n">crashed</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_done</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="k">return</span> <span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">get_state</span><span class="p">(</span><span class="bp">self</span><span class="p">),</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">crash_penalty</span><span class="p">,</span>
                <span class="kc">False</span><span class="p">,</span>
                <span class="kc">True</span><span class="p">,</span>
                <span class="n">info</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_done</span> <span class="o">=</span> <span class="n">truncated</span>

        <span class="k">if</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">n_steps</span> <span class="o">%</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_loader</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_done</span>
        <span class="p">):</span>  <span class="c1"># Calculate validation loss at the end of an epoch</span>
            <span class="n">batch_percentage</span> <span class="o">=</span> <span class="mf">1.0</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">batch_percentage</span> <span class="o">=</span> <span class="mf">0.1</span>

        <span class="n">val_args</span> <span class="o">=</span> <span class="p">[</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">loss_function</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">validation_loader</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">instance</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span>
            <span class="n">batch_percentage</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
        <span class="p">]</span>
        <span class="n">validation_loss</span><span class="p">,</span> <span class="n">validation_accuracy</span> <span class="o">=</span> <span class="n">test</span><span class="p">(</span><span class="o">*</span><span class="n">val_args</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">validation_loss</span> <span class="o">=</span> <span class="n">validation_loss</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">validation_accuracy</span> <span class="o">=</span> <span class="n">validation_accuracy</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
        <span class="k">if</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">min_validation_loss</span> <span class="ow">is</span> <span class="kc">None</span>
            <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">validation_loss</span> <span class="o">&lt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">min_validation_loss</span>
        <span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">min_validation_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">validation_loss</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_done</span><span class="p">:</span>
            <span class="n">val_args</span> <span class="o">=</span> <span class="p">[</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">loss_function</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">test_loader</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">instance</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span>
                <span class="mf">1.0</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
            <span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">test_losses</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">test_accuracies</span> <span class="o">=</span> <span class="n">test</span><span class="p">(</span><span class="o">*</span><span class="n">val_args</span><span class="p">)</span>

        <span class="n">reward</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_reward</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_state</span><span class="p">(</span><span class="bp">self</span><span class="p">),</span> <span class="n">reward</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="n">truncated</span><span class="p">,</span> <span class="n">info</span></div>


<div class="viewcode-block" id="SGDEnv.reset">
<a class="viewcode-back" href="../../../source/benchmark_docs/sgd.html#dacbench.envs.sgd.SGDEnv.reset">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">reset</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">options</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Initialize the neural network, data loaders, etc. for given/random next task.</span>
<span class="sd">        Also perform a single forward/backward pass,</span>
<span class="sd">        not yet updating the neural network parameters.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">options</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">options</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">reset_</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>

        <span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">RandomState</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">initial_seed</span><span class="p">)</span>

        <span class="c1"># Get loaders for instance</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">datasets</span><span class="p">,</span> <span class="n">loaders</span> <span class="o">=</span> <span class="n">random_torchvision_loader</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">instance</span><span class="o">.</span><span class="n">seed</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">instance</span><span class="o">.</span><span class="n">dataset_path</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">instance</span><span class="o">.</span><span class="n">dataset_name</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">instance</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">instance</span><span class="o">.</span><span class="n">fraction_of_dataset</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">instance</span><span class="o">.</span><span class="n">train_validation_ratio</span><span class="p">,</span>
            <span class="n">dataset_config</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">dataset_config</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_loader</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">validation_loader</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">test_loader</span> <span class="o">=</span> <span class="n">loaders</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_generator</span><span class="p">:</span>
            <span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">optimizer_params</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">instance</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">crash_penalty</span><span class="p">,</span>
            <span class="p">)</span> <span class="o">=</span> <span class="n">sgd_utils</span><span class="o">.</span><span class="n">random_instance</span><span class="p">(</span><span class="n">rng</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">datasets</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">instance</span><span class="o">.</span><span class="n">model</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">optimizer_params</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">instance</span><span class="o">.</span><span class="n">optimizer_params</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer_type</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">instance</span><span class="o">.</span><span class="n">optimizer_type</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">info</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_done</span> <span class="o">=</span> <span class="kc">False</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">AdamW</span><span class="p">(</span>
            <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">instance</span><span class="o">.</span><span class="n">optimizer_params</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">()</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loss</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">test_losses</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">validation_loss</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">validation_accuracy</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">min_validation_loss</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">epoch_mode</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">average_loss</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_state</span><span class="p">(</span><span class="bp">self</span><span class="p">),</span> <span class="p">{}</span></div>


<div class="viewcode-block" id="SGDEnv.get_default_reward">
<a class="viewcode-back" href="../../../source/benchmark_docs/sgd.html#dacbench.envs.sgd.SGDEnv.get_default_reward">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">get_default_reward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">_</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;The default reward function.</span>

<span class="sd">        Args:</span>
<span class="sd">            _ (_type_): Empty parameter, which can be used when overriding</span>

<span class="sd">        Returns:</span>
<span class="sd">            float: The calculated reward</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">test_losses</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">reward</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">test_losses</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">test_loader</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">reward</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="k">return</span> <span class="o">-</span><span class="n">reward</span></div>


<div class="viewcode-block" id="SGDEnv.get_default_state">
<a class="viewcode-back" href="../../../source/benchmark_docs/sgd.html#dacbench.envs.sgd.SGDEnv.get_default_state">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">get_default_state</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">_</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Default state function.</span>

<span class="sd">        Args:</span>
<span class="sd">            _ (_type_): Empty parameter, which can be used when overriding</span>

<span class="sd">        Returns:</span>
<span class="sd">            dict: The current state</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">state</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;step&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">c_step</span><span class="p">,</span>
            <span class="s2">&quot;loss&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="p">,</span>
            <span class="s2">&quot;validation_loss&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">validation_loss</span><span class="p">,</span>
            <span class="s2">&quot;validation_accuracy&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">validation_accuracy</span><span class="p">,</span>
            <span class="s2">&quot;done&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_done</span><span class="p">,</span>
        <span class="p">}</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">epoch_mode</span><span class="p">:</span>
            <span class="n">state</span><span class="p">[</span><span class="s2">&quot;average_loss&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">average_loss</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_done</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">test_losses</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">state</span><span class="p">[</span><span class="s2">&quot;test_losses&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">test_losses</span>
            <span class="n">state</span><span class="p">[</span><span class="s2">&quot;test_accuracies&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">test_accuracies</span>
        <span class="k">return</span> <span class="n">state</span></div>


<div class="viewcode-block" id="SGDEnv.render">
<a class="viewcode-back" href="../../../source/benchmark_docs/sgd.html#dacbench.envs.sgd.SGDEnv.render">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">render</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;human&quot;</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Render progress.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;human&quot;</span><span class="p">:</span>
            <span class="n">epoch</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">c_step</span> <span class="o">//</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_loader</span><span class="p">)</span>
            <span class="n">epoch_cutoff</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_steps</span> <span class="o">//</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_loader</span><span class="p">)</span>
            <span class="n">batch</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">c_step</span> <span class="o">%</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_loader</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;prev_lr </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">param_groups</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s1">&#39;lr&#39;</span><span class="p">]</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">n_steps</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="mi">0</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="kc">None</span><span class="si">}</span><span class="s2">, &quot;</span>  <span class="c1"># noqa: E501</span>
                <span class="sa">f</span><span class="s2">&quot;epoch </span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">epoch_cutoff</span><span class="si">}</span><span class="s2">, &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;batch </span><span class="si">{</span><span class="n">batch</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_loader</span><span class="p">)</span><span class="si">}</span><span class="s2">, &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;batch_loss </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="si">}</span><span class="s2">, &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;val_loss </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">validation_loss</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span></div>
</div>

</pre></div>

              </div>
              
              
              <!-- Previous / next buttons -->
<div class='prev-next-area'>
</div>
              
          </main>
          

      </div>
    </div>
  
  <script src="../../../_static/js/index.9ea38e314b9e6d9dab77.js"></script>
<footer class="footer mt-5 mt-md-0">
  <div class="container">
    
    <div class="footer-item">
      <p class="copyright">
    &copy; Copyright 2021, Theresa Eimer, Maximilian Reimer.<br>
</p>
    </div>
    
    <div class="footer-item">
      <p class="sphinx-version">
Created using <a href="http://sphinx-doc.org/">Sphinx</a>
8.1.3. Template is modified version of <a
href="https://pydata-sphinx-theme.readthedocs.io">PyData Sphinx Theme</a>. <br>
</p>
    </div>
    
  </div>
</footer>
  </body>
</html>